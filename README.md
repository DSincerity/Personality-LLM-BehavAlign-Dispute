# Personality-Grounded Behavioral Alignment of LLMs and Humans in Conflict Dialogue

[![AAAI 2026](https://img.shields.io/badge/AAAI-2026-red.svg)](https://aaai.org/conference/aaai/aaai-26/aisi-call/)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-red.svg)](https://www.python.org/downloads/)

This repository contains the official implementation of our **AAAI-2026 paper** on **personality-driven behavioral alignment in conflict dialogue**, providing code and evaluation scripts to compare Big Fiveâ€“prompted LLM agents with humans in dispute resolution conversations.

## ðŸ“„ Paper Information

**Title:** [Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution](TBD)

**Authors:** Deuksin Kwon, Kaleen Shrestha, Spencer Lin, James Hale, Jonathan Gratch, Maja MatariÄ‡, Gale Lucas

**\[Conference\]** AAAI 2026: Special Track on Artificial Intelligence for Social Impact (AISI)
---
<div align="center">
<img src="resources/intro_fig.png" alt="Behavioral Alignment Evaluation Framework Overview" width="650"/>
</div>

## Abstract

Large language models (LLMs) are increasingly used to simulate human behavior in social settings such as legal mediation, negotiation, and dispute resolution. However, it remains unclear if LLMs simulating human behavior are consistent with theoretically proposed mechanisms. Human personality, for instance, may shape how individuals navigate social interactions, including strategic choices and behaviors in emotionally charged interactions. This raises a critical question: \textit{Can LLMs, when prompted with personality traits, reproduce personality-driven differences in human conflict behavior?} To explore this, we introduce an evaluation framework that enables direct comparison of human-human and LLM-LLM behaviors in dispute resolution dialogues with respect to Big Five Inventory (BFI) personality traits. This framework introduces a set of interpretable metrics related to strategic behavior and conflict outcomes. We additionally contribute a novel dataset creation methodology for LLM dispute resolution dialogs with matched scenarios and personality traits with respect to human conversations. Finally, we demonstrate the usage of our evaluation framework with three contemporary closed-source LLMs and show significant divergences in how personality manifests in conflict across different LLMs compared to human data, challenging the assumption that personality-prompted agents can serve as reliable behavioral proxies in socially impactful applications. Our work highlights the need for psychological grounding and rigorous validation in AI simulations before real-world use.

---
## Supplementary Materials of the Paper
You can download the supplementary materials here:
  [Download Supplementary Materials](resources/AAAI_2026_Supplementary_Material.pdf)

---
## Code and Implementation
Technical details and code to be released soon before the AAAI 2026 conference.

---

## Contact

For questions or issues:
- **GitHub Issues**: Report bugs or feature requests
- **Email**: deuksink@usc.edu (Brian Deuksin Kwon) / kshresth@usc.edu (Kaleen Shrestha)

---

## License
This project is licensed under the MIT License.
